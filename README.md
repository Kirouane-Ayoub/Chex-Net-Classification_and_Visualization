# chex-Net


![Screenshot at 2023-04-02 09-30-19](https://user-images.githubusercontent.com/99510125/229341526-00499217-193a-4794-979a-aeccf408947e.png)


CheXNet is a convolutional neural network (CNN) designed for automated interpretation of chest radiographs, developed by Stanford researchers. It was trained to classify 14 different pathologies on chest X-rays, including atelectasis, cardiomegaly, consolidation, edema, effusion, emphysema, fibrosis, hernia, infiltration, mass, nodule, pleural thickening, pneumothorax, and normal.

The CheXNet model architecture is based on a deep residual network (ResNet) with 121 layers. The model was trained using a dataset of over 100,000 chest X-ray images with labels from the National Institutes of Health (NIH) Clinical Center. The dataset was manually labeled by radiologists and used as a benchmark for the CheXNet model's performance.

CheXNet achieved state-of-the-art performance on the NIH dataset, outperforming radiologists in identifying certain pathologies. The model's ability to automate the interpretation of chest X-rays has the potential to improve healthcare outcomes by reducing the time and cost of manual radiological interpretation and increasing diagnostic accuracy.



